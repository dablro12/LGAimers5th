{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 한글 처리\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 한글 폰트 경로 설정\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "\n",
    "# 폰트 이름 얻어오기\n",
    "font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "\n",
    "# 폰트 설정\n",
    "plt.rcParams['font.family'] = font_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from utils.EDA import analysis_임신성공여부, vis_numeric_corr_matrix\n",
    "load_dotenv()\n",
    "df_train = pd.read_csv(os.getenv('TRAIN_DATA_PATH')).drop(columns=['ID'])\n",
    "df_test = pd.read_csv(os.getenv('TEST_DATA_PATH')).drop(columns=['ID'])\n",
    "\n",
    "df_train.head(8).to_csv('train_sample.csv', encoding = 'utf-8-sig', index = False)\n",
    "\n",
    "# df_train = pd.read_csv('data/train.csv').drop(columns=['ID'])\n",
    "# df_test = pd.read_csv('data/test.csv').drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object type 가져오기\n",
    "object_col = df_train.select_dtypes(include='object').columns.tolist()\n",
    "object_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['난자 기증자 나이'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 컬럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 결측 비율 80% 이상 제거\n",
    "# missing_ratio = df_train.isnull().mean()\n",
    "# column_missing = missing_ratio[missing_ratio >= 0.8].index.tolist()\n",
    "\n",
    "# # nunique = 1 제거 \n",
    "# unique_counts = df_train.nunique()\n",
    "# column_nunique = unique_counts[unique_counts == 1].index.tolist()\n",
    "\n",
    "# 컬럼 제거\n",
    "# dropped_columns = list(set(column_missing + column_nunique + ['배란 유도 유형']))\n",
    "dropped_columns = ['불임 원인 - 여성 요인']\n",
    "\n",
    "df_train = df_train.drop(columns=dropped_columns, axis=1)\n",
    "df_test = df_test.drop(columns=dropped_columns, axis=1)\n",
    "\n",
    "print(\"제거된 컬럼 개수:\", len(dropped_columns))\n",
    "print(\"제거된 컬럼:\", dropped_columns)\n",
    "print(\"df_train.shape:\", df_train.shape)\n",
    "print(\"df_test.shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '횟수'를 포함하는 컬럼 찾기\n",
    "count_columns = [col for col in df_train.columns if '횟수' in col]\n",
    "\n",
    "def extract_number(value):\n",
    "    if isinstance(value, str):\n",
    "        return int(value[0])  # 맨 앞자리 숫자로 변환\n",
    "    return value\n",
    "\n",
    "for col in count_columns:\n",
    "    df_train[col] = df_train[col].apply(extract_number).astype(int)\n",
    "    df_test[col] = df_test[col].apply(extract_number).astype(int)\n",
    "print(\"변환된 컬럼:\", count_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특정 시술 유형 - ICSI / 배아 생성 주요 이유 - 현재 시술용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(df):\n",
    "    # 특정 시술 유형 - ICSI\n",
    "    df['특정 시술 유형 - ICSI'] = np.where(df['시술 유형'] != 'IVF', np.nan,  # 시술 유형이 DI\n",
    "                             np.where(df['특정 시술 유형'].str.contains('ICSI', na=False), 1, 0))\n",
    "    df = df.drop(columns=['특정 시술 유형', '배아 생성 주요 이유'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = get_dummies(df_train)\n",
    "df_test = get_dummies(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 남성/여성/부부 주/부 불임 원인 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df):\n",
    "    cols = ['남성 주 불임 원인', '남성 부 불임 원인', \n",
    "            '여성 주 불임 원인', '여성 부 불임 원인',\n",
    "            '부부 주 불임 원인', '부부 부 불임 원인']\n",
    "    \n",
    "    df = df.drop(columns=cols, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = drop_cols(df_train)\n",
    "df_test = drop_cols(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배아 해동 경과일이 0보다 큰 값을 가지는 경우 동결 배아 사용 여부 1로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    df.loc[(df['배아 해동 경과일'] > 0), '동결 배아 사용 여부'] = 1\n",
    "    # df.loc[(df['미세주입된 난자 수'] > 0), '특정 시술 유형 - ICSI'] = 1\n",
    "    return df\n",
    "\n",
    "df_train = process(df_train)\n",
    "df_test = process(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 난자 혼합 경과일, 배아 이식 경과일 groupby median fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(df_train, df_test):\n",
    "    value1 = 0\n",
    "    value2 = df_train[df_train['시술 유형'] == 'IVF'].groupby(['신선 배아 사용 여부', '총 생성 배아 수'])['배아 이식 경과일'].median().fillna(5)\n",
    "    value3 = df_train[(df_train['시술 유형'] == 'IVF') & (df_train['동결 배아 사용 여부'] == 1)].groupby(['배란 자극 여부', '신선 배아 사용 여부', '혼합된 난자 수'])['배아 해동 경과일'].median()\n",
    "\n",
    "    for df in [df_train, df_test]:\n",
    "        # 난자 혼합 경과일\n",
    "        df.loc[df['시술 유형'] == 'IVF', '난자 혼합 경과일'] = df.loc[df['시술 유형'] == 'IVF', '난자 혼합 경과일'].fillna(value1)\n",
    "        # 배아 이식 경과일\n",
    "        df.loc[df['시술 유형'] == 'IVF', '배아 이식 경과일'] = df[df['시술 유형'] == 'IVF'].apply(\n",
    "            lambda row: value2.get((row['신선 배아 사용 여부'], row['총 생성 배아 수']), row['배아 이식 경과일']) \n",
    "            if pd.isna(row['배아 이식 경과일']) else row['배아 이식 경과일'], axis=1\n",
    "        )\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "df_train, df_test = fill_nan(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    epsilon = 1e-5\n",
    "    \n",
    "    # 임신/출산 성공률\n",
    "    df['IVF 시술 대비 임신 성공률'] = df['IVF 임신 횟수'] / df['IVF 시술 횟수']\n",
    "    \n",
    "    # 난자\n",
    "    df['총 난자 수'] = df['수집된 신선 난자 수'] + df['해동 난자 수']\n",
    "    df['난자 사용률'] = df['혼합된 난자 수'] / df['총 난자 수']\n",
    "    \n",
    "    # 배아\n",
    "    df['총 배아 수'] = df['총 생성 배아 수'] + df['해동된 배아 수']\n",
    "    df['미세주입 배아 생성 확률'] = df['미세주입에서 생성된 배아 수'] / df['미세주입된 난자 수']\n",
    "    df['미세주입 배아 이식 확률'] = df['미세주입 배아 이식 수'] / df['미세주입에서 생성된 배아 수']\n",
    "    df['총 배아 생성 확률'] = df['총 배아 수'] / df['총 난자 수']\n",
    "    df['신선 + 기증 + 동결'] = df[['신선 배아 사용 여부', '기증 배아 사용 여부', '동결 배아 사용 여부']].sum(axis=1)\n",
    "    df['배아 저장 비율'] = df['저장된 배아 수'] / (df['총 생성 배아 수'] + epsilon)\n",
    "    \n",
    "    # 이식된 배아 수 관련\n",
    "    df['배아 이식 대비 임신 성공률'] = df['총 임신 횟수'] / df['이식된 배아 수']\n",
    "    df['배아 이식 대비 출산 성공률'] = df['총 출산 횟수'] / df['이식된 배아 수']\n",
    "    df['배아 이식 확률'] = df['이식된 배아 수'] / df['총 배아 수']\n",
    "    df['이식된 배아 대비 이식 기간'] = df['배아 이식 경과일'] / df['이식된 배아 수']\n",
    "    \n",
    "    # [ALERT] Data Leaking # 나이\n",
    "    # df.loc[df['시술 유형'] == 'IVF', '나이 그룹별 평균 생성 배아 수'] = df.groupby('시술 당시 나이')['총 배아 수'].transform('mean')\n",
    "    # df.loc[df['시술 유형'] == 'IVF', '나이 그룹별 평균 이식 배아 수'] = df.groupby('시술 당시 나이')['이식된 배아 수'].transform('mean')\n",
    "\n",
    "    # 기타\n",
    "    df['배란자극 * 단일이식'] = df['배란 자극 여부'] * df['단일 배아 이식 여부']\n",
    "    df['배란자극 * ICSI'] = df['배란 자극 여부'] * df['특정 시술 유형 - ICSI'] \n",
    "    df['경과일 차이 - 난자 혼합 * 배아 이식'] = np.abs(df['배아 이식 경과일'] - df['난자 혼합 경과일'])\n",
    "    df['경과일 차이 - 배아 해동 * 배아 이식'] = np.abs(df['배아 이식 경과일'] - df['배아 해동 경과일'])\n",
    "    df['경과일 합'] = df[['난자 채취 경과일', '난자 해동 경과일', '난자 혼합 경과일', '배아 해동 경과일', '배아 이식 경과일']].sum(axis=1)\n",
    "    \n",
    "    # 바이너리 합\n",
    "    binary_cols = ['배란 자극 여부', '단일 배아 이식 여부', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부']\n",
    "    df['바이너리 합'] = df[binary_cols].sum(axis=1)\n",
    "\n",
    "    # PGD, PGS 합\n",
    "    pgd_pgs = ['착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', 'PGD 시술 여부', 'PGS 시술 여부']\n",
    "    df['PGD * PGS 합'] = df[pgd_pgs].sum(axis=1)\n",
    "    \n",
    "    # 불임 원인 점수\n",
    "    infertility_cols = ['불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', \n",
    "                        '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 면역학적 요인',\n",
    "                        '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태']\n",
    "    for col in infertility_cols:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].map({'Y': 1, 'N': 0})\n",
    "    df['불임원인 수'] = df[infertility_cols].sum(axis=1)\n",
    "    \n",
    "    # 변수 제거\n",
    "    cols = ['총 난자 수', '난자 해동 경과일']\n",
    "    df = df.drop(columns=cols, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = feature_engineering(df_train)\n",
    "df_test = feature_engineering(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시술 유형이 DI인 경우 -1로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def di_null(df):\n",
    "    mask = df['시술 유형'] == 'DI'\n",
    "    columns_to_fill = [col for col in df.columns if col != '임신 시도 또는 마지막 임신 경과 연수']\n",
    "    df.loc[mask, columns_to_fill] = df.loc[mask, columns_to_fill].fillna(-1)\n",
    "    return df\n",
    "\n",
    "df_train = di_null(df_train)\n",
    "df_test = di_null(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결측 비율\n",
    "missing_ratio = df_train.isnull().mean() * 100\n",
    "print(missing_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN, inf 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값 대체\n",
    "def replace_inf_and_nan(df, value_inf, value_na):\n",
    "    df.replace([np.inf, -np.inf], value_inf, inplace=True)  # inf, -inf 변환\n",
    "    df.fillna(value_na, inplace=True)  # NaN 변환\n",
    "    return df\n",
    "\n",
    "# 변환 적용\n",
    "value_inf = 999 # 3 / 0\n",
    "value_na = 999 # 0 / 0\n",
    "df_train = replace_inf_and_nan(df_train, value_inf, value_na)\n",
    "df_test = replace_inf_and_nan(df_test, value_inf, value_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 시술 시기 코드 one-hot encoding\n",
    "# df_train = pd.get_dummies(df_train['시술 시기 코드'], prefix='시술_시기', dtype=int).join(df_train)\n",
    "# df_test = pd.get_dummies(df_test['시술 시기 코드'], prefix='시술_시기', dtype=int).join(df_test)\n",
    "\n",
    "# df_train.drop(columns=['시술 시기 코드'], inplace=True, axis=1)\n",
    "# df_test.drop(columns=['시술 시기 코드'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object 타입 컬럼 확인\n",
    "cat_features = list(df_train.select_dtypes(include=['object']).columns)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder 적용\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder() \n",
    "    df_train[col] = le.fit_transform(df_train[col])  \n",
    "    df_test[col] = le.transform(df_test[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# abs(df_train.corr()['임신 성공 여부']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scaling_cols = [\n",
    "#     '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', \n",
    "#     '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수',\n",
    "#     '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수',\n",
    "#     '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '난자 혼합 경과일',\n",
    "#     '배아 이식 경과일', '경과일_차이', '불임원인_수', '배아저장비율', '이식된 배아 대비 이식 기간',\n",
    "#     '총 배아 수', '나이 그룹별 평균 생성 배아 수', '나이 그룹별 평균 이식 배아 수', '나이 그룹별 평균 배아 이식 경과일'\n",
    "# ]\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# df_train[scaling_cols] = scaler.fit_transform(df_train[scaling_cols])\n",
    "# df_test[scaling_cols] = scaler.transform(df_test[scaling_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def feauture_split(df):\n",
    "#     # FE 후 범주형 자료들 \n",
    "#     cat_boost_columns = [\n",
    "#         \"시술 시기 코드\",\n",
    "#         \"시술 당시 나이\",\n",
    "#         \"시술 유형\",\n",
    "#         \"배란 자극 여부\",\n",
    "#         \"배란 유도 유형\",\n",
    "#         \"불명확 불임 원인\",\n",
    "#         \"난자 출처\",\n",
    "#         \"정자 출처\",\n",
    "#         \"난자 기증자 나이\",\n",
    "#         \"정자 기증자 나이\"\n",
    "#     ]\n",
    "    \n",
    "#     # 수치형 컬럼 선택\n",
    "#     numeric_columns = df.drop(columns=cat_boost_columns).columns.tolist()\n",
    "    \n",
    "#     numeric_columns.remove('임신 성공 여부')\n",
    "    \n",
    "#     return cat_boost_columns, numeric_columns\n",
    "\n",
    "# # Train 데이터 처리 (fit + transform)\n",
    "# cat_boost_columns, numeric_columns = feauture_split(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Scailing - 수치형 범주만\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # 수치형 범주에 대해 scailing \n",
    "# scaler = StandardScaler()\n",
    "# df_train[numeric_columns] = scaler.fit_transform(df_train[numeric_columns])\n",
    "# df_test[numeric_columns] = scaler.transform(df_test[numeric_columns])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # 범주형 범주에 대해 dtype이 int64 이므로 object로 변경\n",
    "# df_train[cat_boost_columns] = df_train[cat_boost_columns].astype('object')\n",
    "# df_test[cat_boost_columns] = df_test[cat_boost_columns].astype('object') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('임신 성공 여부', axis=1)\n",
    "y = df_train['임신 성공 여부']\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 범주형 칼럼에 대한 엔코딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install category_encoders\n",
    "# # # import 라이브러리\n",
    "# import category_encoders as ce\n",
    "# def catboost_encoder_multiclass(X,X_t,y):\n",
    "#     y = y.astype(int)\n",
    "#     enc = ce.OneHotEncoder().fit(y)\n",
    "#     y_onehot = enc.transform(y)\n",
    "#     class_names = y_onehot.columns\n",
    "#     X_obj = X.select_dtypes('object')\n",
    "#     X_t_obj = X_t.select_dtypes('object')\n",
    "#     X = X.select_dtypes(exclude='object')\n",
    "#     X_t = X_t.select_dtypes(exclude='object') \n",
    "#     for class_ in class_names:\n",
    "#         enc = ce.CatBoostEncoder()\n",
    "#         enc.fit(X_obj,y_onehot[class_])\n",
    "#         temp = enc.transform(X_obj)\n",
    "#         temp_t = enc.transform(X_t_obj)\n",
    "#         temp.columns = [str(x)+'_'+str(class_) for x in temp.columns]\n",
    "#         temp_t.columns = [str(x)+'_'+str(class_) for x in temp_t.columns]\n",
    "#         X = pd.concat([X,temp],axis=1)\n",
    "#         X_t = pd.concat([X_t,temp_t],axis=1)\n",
    "#     return X, X_t\n",
    "\n",
    "# X, X_test = catboost_encoder_multiclass(X,X_test,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified K-Fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def get_catboost_model(use_gpu=False):\n",
    "    \"\"\"\n",
    "    CatBoost 생성 함수\n",
    "    use_gpu=True -> GPU 설정\n",
    "    use_gpu=False -> CPU 설정\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'iterations': 745,\n",
    "        'learning_rate': 0.038577,\n",
    "        'depth': 8,\n",
    "        'l2_leaf_reg': 9.587765,\n",
    "        'random_strength': 0.0,  # 0으로 설정\n",
    "        'min_data_in_leaf': 59,\n",
    "        'leaf_estimation_iterations': 1,\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'verbose': 100,\n",
    "        'random_seed': 123\n",
    "    }\n",
    "    if use_gpu:\n",
    "        params['task_type'] = 'GPU'\n",
    "        params['devices'] = '0'   # GPU 디바이스 인덱스\n",
    "    else:\n",
    "        params['task_type'] = 'CPU'\n",
    "        # GPU 관련 매개변수 제거 (또는 무시)\n",
    "        # params.pop('devices', None)\n",
    "\n",
    "    return CatBoostClassifier(**params)\n",
    "\n",
    "\n",
    "def get_xgb_model(use_gpu=False):\n",
    "    \"\"\"\n",
    "    XGBoost 생성 함수\n",
    "    use_gpu=True -> GPU 설정(tree_method='gpu_hist', gpu_id=0)\n",
    "    use_gpu=False -> CPU 설정(tree_method='auto' 혹은 'hist')\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.03734198499634527,\n",
    "        'n_estimators': 559,\n",
    "        'min_child_weight': 7,\n",
    "        'subsample': 0.7737425087025644,\n",
    "        'colsample_bytree': 0.7375994851305036,\n",
    "        'gamma': 0.3585439077860097,\n",
    "        'reg_alpha': 0.0007202349503619253,\n",
    "        'reg_lambda': 0.0025871862951435433,\n",
    "        'random_state': 123,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss',\n",
    "    }\n",
    "    if use_gpu:\n",
    "        params['tree_method'] = 'gpu_hist'\n",
    "        params['gpu_id'] = 0\n",
    "    else:\n",
    "        # CPU 사용 시 일반 히스토그램 방식을 적용\n",
    "        params['tree_method'] = 'hist'\n",
    "        # params.pop('gpu_id', None)\n",
    "\n",
    "    return XGBClassifier(**params)\n",
    "\n",
    "\n",
    "def get_lgbm_model(use_gpu=False):\n",
    "    \"\"\"\n",
    "    LightGBM 생성 함수\n",
    "    use_gpu=True -> GPU 설정(device='gpu')\n",
    "    use_gpu=False -> CPU 설정(device='cpu')\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'n_estimators': 252,\n",
    "        'learning_rate': 0.080232,\n",
    "        'max_depth': 8,\n",
    "        'num_leaves': 18,\n",
    "        'subsample': 0.875359,\n",
    "        'colsample_bytree': 0.573221,\n",
    "        'min_child_samples': 24,\n",
    "        'min_child_weight': 0.027338,\n",
    "        'reg_lambda': 1.0,\n",
    "        'reg_alpha': 0.000013,\n",
    "        'random_state': 123\n",
    "    }\n",
    "\n",
    "    if use_gpu:\n",
    "        params['device'] = 'gpu'\n",
    "        params['gpu_device_id'] = 0\n",
    "        params['gpu_platform_id'] = 0\n",
    "    else:\n",
    "        params['device'] = 'cpu'\n",
    "        # GPU 관련 파라미터는 무시되거나 제거 가능\n",
    "        # params.pop('gpu_device_id', None)\n",
    "        # params.pop('gpu_platform_id', None)\n",
    "\n",
    "    return LGBMClassifier(**params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    'CatBoost': lambda: get_catboost_model(use_gpu=True),\n",
    "    'XGBoost': lambda: get_xgb_model(use_gpu=True),\n",
    "    'LightGBM': lambda: get_lgbm_model(use_gpu=True),\n",
    "}\n",
    "# models_info = {\n",
    "#     'CatBoost': lambda: get_catboost_model(use_gpu=False),\n",
    "#     'XGBoost': lambda: get_xgb_model(use_gpu=False),\n",
    "#     'LightGBM': lambda: get_lgbm_model(use_gpu=False),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {model_name: [] for model_name in models_info.keys()}\n",
    "feature_importances = {model_name: [] for model_name in models_info.keys()}\n",
    "test_proba = {model_name: [] for model_name in models_info.keys()}\n",
    "\n",
    "# ========================\n",
    "# 4) 평가 함수 정의\n",
    "# ========================\n",
    "def evaluate_model(model, X_val, y_true):\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'ROC AUC Score': roc_auc_score(y_true, y_pred_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 20\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
    "    print(f\"===== Fold {fold} =====\")\n",
    "\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # 모델별로 학습 및 평가\n",
    "    for model_name, model_constructor in models_info.items():\n",
    "        # (1) 모델 생성\n",
    "        model = model_constructor()\n",
    "\n",
    "        # (2) 모델 훈련\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # (3) 검증 평가\n",
    "        fold_score = evaluate_model(model, X_val, y_val)\n",
    "        metrics[model_name].append(fold_score)\n",
    "\n",
    "        # (4) 피처 중요도\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importances[model_name].append(model.feature_importances_)\n",
    "        else:\n",
    "            # 일부 모델(예: VotingClassifier 등)은 feature_importances_가 없을 수도 있으니 None 처리\n",
    "            feature_importances[model_name].append(None)\n",
    "\n",
    "        # (5) 테스트 세트 예측 (확률)\n",
    "        test_proba[model_name].append(model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (예시) 특정 모델에 대해 Fold별 ROC AUC 평균\n",
    "for model_name in models_info.keys():\n",
    "    roc_list = [score['ROC AUC Score'] for score in metrics[model_name]]\n",
    "    avg_roc = np.mean(roc_list)\n",
    "    print(f\"\\n=== {model_name} - ROC AUC (Fold {n_splits}개) ===\")\n",
    "    print(\"Fold별  :\", roc_list)\n",
    "    print(\"평균 ROC AUC:\", avg_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Stratified K-Fold 설정\n",
    "# n_splits = 5\n",
    "# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "\n",
    "# metrics = {model: [] for model in ['CatBoost']} # Ensemble\n",
    "# feature_importances = {model: [] for model in ['CatBoost']}\n",
    "# test_proba = {model: [] for model in ['CatBoost']} # Ensemble\n",
    "\n",
    "# # metrics = {model: [] for model in ['CatBoost', 'XGBoost', 'LightGBM', 'AdaBoost']} # Ensemble\n",
    "# # feature_importances = {model: [] for model in ['CatBoost', 'XGBoost', 'LightGBM', 'AdaBoost']}\n",
    "# # test_proba = {model: [] for model in ['CatBoost', 'XGBoost', 'LightGBM', 'AdaBoost']} # Ensemble\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "#     print(f\"===== Fold {fold} =====\")\n",
    "\n",
    "#     X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#     # 모델 정의\n",
    "#     cat_model = CatBoostClassifier(\n",
    "#     iterations=745, \n",
    "#     learning_rate=0.038577, \n",
    "#     depth=8, \n",
    "#     l2_leaf_reg=9.587765,\n",
    "#     # subsample=0.748324, \n",
    "#     random_strength=0.0,  # 0으로 설정\n",
    "#     min_data_in_leaf=59, \n",
    "#     leaf_estimation_iterations=1, \n",
    "#     loss_function='Logloss', \n",
    "#     eval_metric='AUC', \n",
    "#     verbose=100, \n",
    "#     random_seed=123,\n",
    "#     task_type=\"GPU\",\n",
    "#     devices='0',\n",
    "#     )\n",
    "\n",
    "#     xgb_model = XGBClassifier(\n",
    "#         max_depth=4,\n",
    "#         learning_rate=0.03734198499634527,\n",
    "#         n_estimators=559,\n",
    "#         min_child_weight=7,\n",
    "#         subsample=0.7737425087025644,\n",
    "#         colsample_bytree=0.7375994851305036,\n",
    "#         gamma=0.3585439077860097,\n",
    "#         reg_alpha=0.0007202349503619253,\n",
    "#         reg_lambda=0.0025871862951435433,\n",
    "#         random_state=123,\n",
    "#         use_label_encoder=False,  \n",
    "#         eval_metric='logloss',\n",
    "#         tree_method='gpu_hist', gpu_id = 0\n",
    "#     )\n",
    "\n",
    "#     lgbm_model = LGBMClassifier(\n",
    "#         n_estimators=252, learning_rate=0.080232, max_depth=8, num_leaves=18,\n",
    "#         subsample=0.875359, colsample_bytree=0.573221,\n",
    "#         min_child_samples=24, min_child_weight = 0.027338,\n",
    "#         reg_lambda=1.0, reg_alpha=0.000013, \n",
    "#         random_state=123,\n",
    "#         device='gpu', gpu_device_id = 0, gpu_platform_id = 0,\n",
    "#     )\n",
    "\n",
    "#     # gb_model = GradientBoostingClassifier(\n",
    "#     #         n_estimators=263,\n",
    "#     #         learning_rate=0.003550,\n",
    "#     #         max_depth=5,\n",
    "#     #         subsample=0.65,\n",
    "#     #         max_features=0.81,\n",
    "#     #         random_state=123,\n",
    "#     #     )\n",
    "    \n",
    "#     # adaboost_model = AdaBoostClassifier(\n",
    "#     #     estimator=DecisionTreeClassifier(max_depth=8, min_samples_split=10, min_samples_leaf=5, random_state=123),\n",
    "#     #     n_estimators=745, learning_rate=0.038577,\n",
    "#     #     algorithm=\"SAMME\", random_state=123,\n",
    "#     # )\n",
    "#     # # weight = np.array([0.739903, 0.738065])\n",
    "#     # ensemble_model = VotingClassifier(\n",
    "#     #     ## all \n",
    "#     #     # estimators=[('catboost', cat_model), ('xgboost', xgb_model), ('lightgbm', lgbm_model), ('adaboost', adaboost_model)],\n",
    "#     #     # voting='soft', weights=[1, 1, 1, 0.8]\n",
    "#     #     ## Cat(0.5) + XGBoost(0.5)\n",
    "#     #     estimators=[('catboost', cat_model), ('xgboost', xgb_model)],\n",
    "#     #     voting='soft', weights=[weight[0]/weight.sum(), weight[1]/weight.sum()]\n",
    "#     # )\n",
    "\n",
    "\n",
    "#     # 모델 학습\n",
    "#     # for model in [cat_model]: # CatBoost\n",
    "#     # for model in [xgb_model]: # XGBoost\n",
    "#     for model in [lgbm_model]: # lgbm_model\n",
    "#     # for model in [adaboost_model]: # Adaboost\n",
    "#     # for model in [ensemble_model]: # XGBoost\n",
    "# #     for model in [cat_model, xgb_model, lgbm_model, adaboost_model]: # ensemble_model\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#     # 평가 함수\n",
    "#     def evaluate_model(model, X_val, y_true):\n",
    "#         y_pred = model.predict(X_val)\n",
    "#         y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#         return {\n",
    "#             'Accuracy': accuracy_score(y_true, y_pred),\n",
    "#             'Precision': precision_score(y_true, y_pred),\n",
    "#             'Recall': recall_score(y_true, y_pred),\n",
    "#             'F1 Score': f1_score(y_true, y_pred),\n",
    "#             'ROC AUC Score': roc_auc_score(y_true, y_pred_proba)\n",
    "#         }\n",
    "\n",
    "#     # 평가 및 변수 중요도 저장\n",
    "#     # for model_name, model in zip(metrics.keys(), [cat_model]): # CatBoost\n",
    "#     # for model_name, model in zip(metrics.keys(), [xgb_model]): # XGBoost\n",
    "#     for model_name, model in zip(metrics.keys(), [lgbm_model]): # XGBoost\n",
    "#     # for model_name, model in zip(metrics.keys(), [ensemble_model]):\n",
    "#         metrics[model_name].append(evaluate_model(model, X_val, y_val))\n",
    "\n",
    "#     # for model_name, model in zip(['CatBoost'], [cat_model]): # CatBoost\n",
    "#     # for model_name, model in zip(['CatBoost'], [xgb_model]): # XGBoost\n",
    "#     for model_name, model in zip(['CatBoost'], [lgbm_model]): # lgbm\n",
    "#     # for model_name, model in zip(['CatBoost'], [adaboost_model]): # AdaBoost\n",
    "#     # for model_name, model in zip(['CatBoost'], [ensemble_model]): # Ensemble\n",
    "#         feature_importances[model_name].append(model.feature_importances_)\n",
    "        \n",
    "#     # 테스트 데이터 예측 확률 저장\n",
    "#     # test_proba['CatBoost'].append(cat_model.predict_proba(X_test)[:, 1])\n",
    "#     # test_proba['CatBoost'].append(xgb_model.predict_proba(X_test)[:, 1])\n",
    "#     test_proba['CatBoost'].append(lgbm_model.predict_proba(X_test)[:, 1])\n",
    "#     # test_proba['CatBoost'].append(adaboost_model.predict_proba(X_test)[:, 1])\n",
    "#     # test_proba['CatBoost'].append(ensemble_model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # test_proba['XGBoost'].append(xgb_model.predict_proba(X_test)[:, 1])\n",
    "# #     test_proba['LightGBM'].append(lgbm_model.predict_proba(X_test)[:, 1])\n",
    "# #     test_proba['AdaBoost'].append(adaboost_model.predict_proba(X_test)[:, 1])\n",
    "# #     test_proba['Ensemble'].append(ensemble_model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===== Stratified K-Fold 평균 성능 =====\")\n",
    "for model_name, model_metrics in metrics.items():\n",
    "    # 모든 fold의 val auc 합계 계산\n",
    "    total_val_auc = sum(fold_metric['ROC AUC Score'] for fold_metric in model_metrics)\n",
    "    \n",
    "    # 각 metric별 가중 평균 계산\n",
    "    weighted_avg_metrics = {\n",
    "        metric: sum((fold_metric['ROC AUC Score'] / total_val_auc) * fold_metric[metric]\n",
    "                    for fold_metric in model_metrics)\n",
    "        for metric in model_metrics[0]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n== {model_name} Model ==\")\n",
    "    for metric, value in weighted_avg_metrics.items():\n",
    "        print(f\"{metric}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 최종 변수 중요도 평균 계산\n",
    "df_fi_list = []\n",
    "for model_name, fi_list in feature_importances.items():\n",
    "    avg_importance = np.mean(fi_list, axis=0)\n",
    "    df_fi = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        model_name: avg_importance \n",
    "    })\n",
    "\n",
    "    df_fi = df_fi.sort_values(by=model_name, ascending=False).reset_index(drop=True)\n",
    "    df_fi_list.append(df_fi)\n",
    "    \n",
    "df_fi_final = pd.concat(df_fi_list, axis=1)\n",
    "df_fi_final.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abs(df_train.corr()['임신 성공 여부']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # catboost 기준 변수 중요도 0.05 미만 변수 제거\n",
    "# df_cat = df_fi_final.iloc[:, :2]\n",
    "# df_selected = df_cat[df_cat['CatBoost'] > 0.05]\n",
    "# selected_features = df_selected['Feature'].tolist()\n",
    "\n",
    "# # 중요도가 높은 피처만 선택하여 새로운 데이터 생성\n",
    "# X = X[selected_features]\n",
    "# X_test = X_test[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Stratified K-Fold 설정\n",
    "# n_splits = 5\n",
    "# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "\n",
    "# metrics = {model: [] for model in ['CatBoost']} # Ensemble\n",
    "# feature_importances = {model: [] for model in ['CatBoost']}\n",
    "# test_proba = {model: [] for model in ['CatBoost']} # Ensemble\n",
    "\n",
    "# # metrics = {model: [] for model in ['CatBoost', 'XGBoost', 'LightGBM', 'AdaBoost']} # Ensemble\n",
    "# # feature_importances = {model: [] for model in ['CatBoost', 'XGBoost', 'LightGBM', 'AdaBoost']}\n",
    "# # test_proba = {model: [] for model in ['CatBoost', 'XGBoost', 'LightGBM', 'AdaBoost']} # Ensemble\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "#     print(f\"===== Fold {fold} =====\")\n",
    "\n",
    "#     X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#     # 모델 정의\n",
    "#     cat_model = CatBoostClassifier(\n",
    "#     iterations=745, \n",
    "#     learning_rate=0.038577, \n",
    "#     depth=8, \n",
    "#     l2_leaf_reg=9.587765,\n",
    "#     subsample=0.748324, \n",
    "#     random_strength=0.0,  # 0으로 설정\n",
    "#     min_data_in_leaf=59, \n",
    "#     leaf_estimation_iterations=1, \n",
    "#     loss_function='Logloss', \n",
    "#     eval_metric='AUC', \n",
    "#     verbose=100, \n",
    "#     random_seed=123)\n",
    "\n",
    "#     # xgb_model = XGBClassifier(\n",
    "#     #     n_estimators=700, learning_rate=0.03, max_depth=7, min_child_weight=3,\n",
    "#     #     gamma=0.1, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1,\n",
    "#     #     reg_lambda=1.0, verbosity=1, random_state=123\n",
    "#     # )\n",
    "\n",
    "#     # lgbm_model = LGBMClassifier(\n",
    "#     #     n_estimators=700, learning_rate=0.03, max_depth=-1, num_leaves=64,\n",
    "#     #     min_child_samples=20, subsample=0.8, colsample_bytree=0.8,\n",
    "#     #     reg_alpha=0.1, reg_lambda=1.0, verbosity=1, random_state=123\n",
    "#     # )\n",
    "    \n",
    "#     # adaboost_model = AdaBoostClassifier(\n",
    "#     #     estimator=DecisionTreeClassifier(max_depth=2, min_samples_split=10, min_samples_leaf=5, random_state=123),\n",
    "#     #     n_estimators=500, learning_rate=0.05,\n",
    "#     #     algorithm=\"SAMME\", random_state=123\n",
    "#     # )\n",
    "    \n",
    "# #     ensemble_model = VotingClassifier(\n",
    "# #         estimators=[('catboost', cat_model), ('xgboost', xgb_model), ('lightgbm', lgbm_model), ('adaboost', adaboost_model)],\n",
    "# #         voting='soft', weights=[1, 1, 1, 0.8]\n",
    "# #     )\n",
    "\n",
    "\n",
    "#     # 모델 학습\n",
    "#     for model in [cat_model]: # ensemble_model\n",
    "# #     for model in [cat_model, xgb_model, lgbm_model, adaboost_model]: # ensemble_model\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#     # 평가 함수\n",
    "#     def evaluate_model(model, X_val, y_true):\n",
    "#         y_pred = model.predict(X_val)\n",
    "#         y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "#         # X_val의 이식된 배아 수가 0이면 y_pred_proba가 0이 되게 함\n",
    "#         y_pred_proba = np.where(X_val['이식된 배아 수'] == 0, 0, y_pred_proba)\n",
    "\n",
    "#         return {\n",
    "#             'Accuracy': accuracy_score(y_true, y_pred),\n",
    "#             'Precision': precision_score(y_true, y_pred),\n",
    "#             'Recall': recall_score(y_true, y_pred),\n",
    "#             'F1 Score': f1_score(y_true, y_pred),\n",
    "#             'ROC AUC Score': roc_auc_score(y_true, y_pred_proba)\n",
    "#         }\n",
    "\n",
    "#     # 평가 및 변수 중요도 저장\n",
    "#     for model_name, model in zip(metrics.keys(), [cat_model]): # ensemble_model\n",
    "#         metrics[model_name].append(evaluate_model(model, X_val, y_val))\n",
    "\n",
    "#     for model_name, model in zip(['CatBoost'], [cat_model]):\n",
    "#         feature_importances[model_name].append(model.feature_importances_)\n",
    "        \n",
    "#     # 테스트 데이터 예측 확률 저장\n",
    "#     # [ADD] 이식된 배아 수가 0이면 0으로 예측하도록 함.\n",
    "#     y_test_proba = cat_model.predict_proba(X_test)[:, 1]\n",
    "#     y_test_proba = np.where(X_test['이식된 배아 수'] == 0, 0, y_test_proba)\n",
    "    \n",
    "#     test_proba['CatBoost'].append(y_test_proba)\n",
    "# #     test_proba['XGBoost'].append(xgb_model.predict_proba(X_test)[:, 1])\n",
    "# #     test_proba['LightGBM'].append(lgbm_model.predict_proba(X_test)[:, 1])\n",
    "# #     test_proba['AdaBoost'].append(adaboost_model.predict_proba(X_test)[:, 1])\n",
    "# #     test_proba['Ensemble'].append(ensemble_model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 평가 지표 평균 출력\n",
    "# print(\"===== Stratified K-Fold 평균 성능 =====\")\n",
    "# for model_name, model_metrics in metrics.items():\n",
    "#     avg_metrics = {metric: np.mean([fold_metric[metric] for fold_metric in model_metrics]) for metric in model_metrics[0]}\n",
    "    \n",
    "#     print(f\"\\n== {model_name} Model ==\")\n",
    "#     for metric, value in avg_metrics.items():\n",
    "#         print(f\"{metric}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Best AUC 기록한 모델의 pred_proba로 선택\n",
    "# pred_proba = np.mean(test_proba['CatBoost'], axis=0)\n",
    "# # pred_proba = np.mean(test_proba['XGBoost'], axis=0)\n",
    "# # pred_proba = np.mean(test_proba['LightGBM'], axis=0)\n",
    "# # pred_proba = np.mean(test_proba['AdaBoost'], axis=0)\n",
    "# # pred_proba = np.mean(test_proba['Ensemble'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_scores = np.array([fold_metrics['ROC AUC Score'] for fold_metrics in metrics['CatBoost']])\n",
    "\n",
    "weights = roc_auc_scores / np.sum(roc_auc_scores)  # 합이 1이 되도록 정규화\n",
    "\n",
    "test_proba_array = np.array(test_proba['CatBoost'])  # (n_folds, n_samples) 형태\n",
    "\n",
    "pred_proba = np.average(test_proba_array, axis=0, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "# sample_submission.head()\n",
    "\n",
    "sample_submission = pd.read_csv(os.getenv('SUBMISSION_DATA_PATH'))\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission['probability'] = pred_proba\n",
    "# # 저장\n",
    "# sample_submission.to_csv('data/submission.csv', index=False)\n",
    "# sample_submission.head()\n",
    "\n",
    "sample_submission['probability'] = pred_proba\n",
    "# 저장\n",
    "import datetime \n",
    "now = datetime.datetime.now()\n",
    "save_path = os.path.join(f'./log/submission/{now.strftime(\"%Y%m%d_%H%M%S\")}_{weighted_avg_metrics[\"ROC AUC Score\"]:.5f}_eiden.csv')\n",
    "sample_submission.to_csv(save_path, index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인용\n",
    "submission = pd.read_csv(save_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
